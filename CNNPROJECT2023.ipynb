{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f499a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56b72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"C:/Users/user/Desktop/Uni/Viti 3/Semestri 1/Artificial Intelligence/project_dataset/train\"\n",
    "test_path=\"C:/Users/user/Desktop/Uni/Viti 3/Semestri 1/Artificial Intelligence/project_dataset/test\"\n",
    "val_path=\"C:/Users/user/Desktop/Uni/Viti 3/Semestri 1/Artificial Intelligence/project_dataset/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca63c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 100\n",
    "img_width = 100\n",
    "\n",
    "x_train=[]\n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "\n",
    "    sub_path=train_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(img_height,img_width))\n",
    "\n",
    "        x_train.append(img_arr)\n",
    "\n",
    "x_test=[]\n",
    "\n",
    "for folder in os.listdir(test_path):\n",
    "\n",
    "    sub_path=test_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(img_height,img_width))\n",
    "\n",
    "        x_test.append(img_arr)\n",
    "\n",
    "x_val=[]\n",
    "\n",
    "for folder in os.listdir(val_path):\n",
    "\n",
    "    sub_path=val_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(img_height,img_width))\n",
    "\n",
    "        x_val.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d7481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(x_train)\n",
    "test_x=np.array(x_test)\n",
    "val_x=np.array(x_val)\n",
    "\n",
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0\n",
    "val_x=val_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702e50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86b0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4432 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (img_height,img_width),\n",
    "                                                 batch_size = 8,\n",
    "                                                 class_mode = 'sparse')\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (img_height,img_width),\n",
    "                                            batch_size = 8,\n",
    "                                            class_mode = 'sparse')\n",
    "val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                            target_size = (img_height,img_width),\n",
    "                                            batch_size = 8,\n",
    "                                            class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91be243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=training_set.classes\n",
    "test_y=test_set.classes\n",
    "val_y=val_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7202cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORMAL': 0, 'PNEUMONIA': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac8d304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4432,), (624,), (800,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape,test_y.shape,val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc97cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([ \n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(2, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),  \n",
    "  layers.Conv2D(4, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9882819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "    \n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa0bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 100, 100, 2)       56        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 50, 50, 2)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 4)         76        \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 25, 8)         296       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                18464     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,126\n",
      "Trainable params: 20,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb6a1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
    "#Early stopping to avoid overfitting of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93f41a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "554/554 [==============================] - 76s 135ms/step - loss: 0.6935 - accuracy: 0.2155 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 72s 129ms/step - loss: 0.6931 - accuracy: 0.2141 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 72s 129ms/step - loss: 0.6931 - accuracy: 0.2141 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 72s 129ms/step - loss: 0.6931 - accuracy: 0.2141 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 68s 123ms/step - loss: 0.6931 - accuracy: 0.2141 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "history = model.fit(\n",
    "  train_x,\n",
    "  train_y,\n",
    "  validation_data=(val_x,val_y),\n",
    "  epochs=epochs,\n",
    "  callbacks=[early_stop],\n",
    "  batch_size=8,\n",
    "  shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96fa038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 8ms/step - loss: 0.6931 - accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931473612785339, 0.625]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x,test_y,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d79699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa238690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "y_pred=model.predict(test_x)\n",
    "y_pred=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c608ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.62      0.77       624\n",
      "\n",
      "    accuracy                           0.62       624\n",
      "   macro avg       0.50      0.31      0.38       624\n",
      "weighted avg       1.00      0.62      0.77       624\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\proect_work\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\envs\\proect_work\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\envs\\proect_work\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#get classification report\n",
    "print(classification_report(y_pred,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4fe298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0]\n",
      " [234 390]]\n"
     ]
    }
   ],
   "source": [
    "#get confusion matrix\n",
    "print(confusion_matrix(y_pred,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14471351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
